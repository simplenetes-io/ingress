api: 1.0.0-beta1
runtime: podman
podVersion: 0.0.15

volumes:
      # conf name hardcoded into the ingress generator and cannot be changed.
      # The generated haproxy.conf file is written to it inside the cluster project `cluster_dir/_config/ingress/conf` directory.
    - name: conf
      type: config

      # Certs provided by the auto issuer pod (letsencrypt pod) are fetched to this volume.
      # If these auto certs are not used, this volume must still be present otherwise the haproxy.conf will fail.
    - name: autocerts
      type: ramdisk
      size: 28M

      # User provided certs, such as Extended Validation certificates which include human validation.
      # Certs are to be placed here (`cluster_dir/_config/ingress/usercerts`) manually be the user and synced.
    - name: usercerts
      type: config
      # We can make this into an encrypted secret (when that feature is implemented in snt).
      encrypted: false
containers:
#ifdef ${useFetcher}
    - name: fetcher
      # TODO: change image name to actual repo
      image: ingress-fetcher:0.0.2
      # Restart this container once each 12 hours to fetch any updated certificates.
      restart: on-interval:43200
      env:
            # This is the cluster port the Letsencrypt pod is listening to.
            # Set it as en env variable which our "fetcher" program will use.
          - name: autoCertClusterPort
            value: 64000
      mounts:
          # This is the RAMDISK defined above, to here fetched certificates are written.
          # The destination is hardcoded into the fetcher program.
          - volume: autocerts
            dest: /mnt/autocerts
      startupProbe:
          # Allow 20 seconds for the container to get started.
          timeout: 20

          # Our probe is simply that we wait for the container to exit with code 0.
          exit: true

          # Signal the haproxy container to reload when we exit successfully.
          # This will make the haproxy container reload once every 12 h, regardless of there are new certs or not. But there's no harm in doing this so instead
          # of complicating the logic of not reloading when there are no new certs, we KISS it and only provide this simpler path.
          # Since we have a startup probe, that means that the pod creation process will fail if this container does not exit properly.
          signal:
              - container: haproxy
#endif
    - name: haproxy
      image: haproxy:2.1.3-alpine
      restart: always
      signal:
          - sig: USR2
      command:
          - haproxy
          - -f
          - /mnt/conf/haproxy.cfg
          - -W
      mounts:
            # The destinations for mounting certs are hardcoded into the ingress haproxy.cfg generator and must not be changed.
          - volume: usercerts
            dest: /mnt/usercerts
          - volume: autocerts
            dest: /mnt/autocerts
          - volume: conf
            dest: /mnt/conf
      expose:
#ifndef ${DEVMODE}
            # These ports we mount only in real mode
          - targetPort: 80
            hostPort: 80
          - targetPort: 443
            hostPort: 443
#endif
#ifdef ${DEVMODE}
            # These ports we mount in dev mode
          - targetPort: 80
            hostPort: 8080
          - targetPort: 443
            hostPort: 4434
#endif
